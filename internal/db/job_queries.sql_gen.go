// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: job_queries.sql

package db

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const archiveJob = `-- name: ArchiveJob :exec
UPDATE download_jobs
SET archived = TRUE,
    updated_at = NOW()
WHERE id = $1
`

// ArchiveJob marks a job as archived (soft delete).
//
//	UPDATE download_jobs
//	SET archived = TRUE,
//	    updated_at = NOW()
//	WHERE id = $1
func (q *Queries) ArchiveJob(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, archiveJob, id)
	return err
}

const archiveJobs = `-- name: ArchiveJobs :exec
UPDATE download_jobs
SET archived = TRUE,
    updated_at = NOW()
WHERE id = ANY($1::uuid[])
`

// ArchiveJobs marks multiple jobs as archived (batch operation).
//
//	UPDATE download_jobs
//	SET archived = TRUE,
//	    updated_at = NOW()
//	WHERE id = ANY($1::uuid[])
func (q *Queries) ArchiveJobs(ctx context.Context, jobIds []pgtype.UUID) error {
	_, err := q.db.Exec(ctx, archiveJobs, jobIds)
	return err
}

const cancelDownloadJob = `-- name: CancelDownloadJob :exec
UPDATE download_jobs
SET status = 'failed',
    last_error = 'Cancelled by user',
    finished_at = NOW(),
    process_pid = NULL,
    updated_at = NOW()
WHERE id = $1
`

// CancelDownloadJob marks a job as cancelled.
//
//	UPDATE download_jobs
//	SET status = 'failed',
//	    last_error = 'Cancelled by user',
//	    finished_at = NOW(),
//	    process_pid = NULL,
//	    updated_at = NOW()
//	WHERE id = $1
func (q *Queries) CancelDownloadJob(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, cancelDownloadJob, id)
	return err
}

const dequeueDownloadJob = `-- name: DequeueDownloadJob :one
WITH cte AS (
    SELECT id
    FROM download_jobs
    WHERE status = 'queued'
    ORDER BY created_at
    LIMIT 1
    FOR UPDATE SKIP LOCKED
)
UPDATE download_jobs
SET status = 'processing',
    attempts = attempts + 1,
    started_at = COALESCE(started_at, NOW()),
    updated_at = NOW()
WHERE id IN (SELECT id FROM cte)
RETURNING id, created_at, updated_at, url, archived_by, status, attempts, last_error, started_at, finished_at, spool_dir, info_json_path, video_id, refresh, process_pid, archived, extra_args
`

// DequeueDownloadJob claims one queued download job.
//
//	WITH cte AS (
//	    SELECT id
//	    FROM download_jobs
//	    WHERE status = 'queued'
//	    ORDER BY created_at
//	    LIMIT 1
//	    FOR UPDATE SKIP LOCKED
//	)
//	UPDATE download_jobs
//	SET status = 'processing',
//	    attempts = attempts + 1,
//	    started_at = COALESCE(started_at, NOW()),
//	    updated_at = NOW()
//	WHERE id IN (SELECT id FROM cte)
//	RETURNING id, created_at, updated_at, url, archived_by, status, attempts, last_error, started_at, finished_at, spool_dir, info_json_path, video_id, refresh, process_pid, archived, extra_args
func (q *Queries) DequeueDownloadJob(ctx context.Context) (*DownloadJob, error) {
	row := q.db.QueryRow(ctx, dequeueDownloadJob)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.URL,
		&i.ArchivedBy,
		&i.Status,
		&i.Attempts,
		&i.LastError,
		&i.StartedAt,
		&i.FinishedAt,
		&i.SpoolDir,
		&i.InfoJsonPath,
		&i.VideoID,
		&i.Refresh,
		&i.ProcessPid,
		&i.Archived,
		&i.ExtraArgs,
	)
	return &i, err
}

const dequeueIngestJob = `-- name: DequeueIngestJob :one
WITH cte AS (
    SELECT id
    FROM ingest_jobs
    WHERE status = 'queued'
      AND attempts < 5
    ORDER BY created_at
    LIMIT 1
    FOR UPDATE SKIP LOCKED
)
UPDATE ingest_jobs AS ij
SET status = 'processing',
    attempts = ij.attempts + 1,
    started_at = COALESCE(ij.started_at, NOW()),
    updated_at = NOW()
FROM download_jobs AS dj
WHERE ij.id IN (SELECT id FROM cte)
  AND dj.id = ij.download_job_id
RETURNING
    ij.id AS ingest_job_id,
    ij.download_job_id,
    dj.url AS url,
    dj.archived_by AS archived_by,
    dj.refresh AS refresh,
    dj.spool_dir AS spool_dir,
    dj.info_json_path AS info_json_path,
    dj.video_id AS video_id,
    ij.asset_scope AS asset_scope,
    dj.extra_args AS extra_args
`

type DequeueIngestJobRow struct {
	IngestJobID   pgtype.UUID `db:"ingest_job_id" json:"IngestJobID"`
	DownloadJobID pgtype.UUID `db:"download_job_id" json:"DownloadJobID"`
	URL           string      `db:"url" json:"Url"`
	ArchivedBy    pgtype.UUID `db:"archived_by" json:"ArchivedBy"`
	Refresh       bool        `db:"refresh" json:"Refresh"`
	SpoolDir      *string     `db:"spool_dir" json:"SpoolDir"`
	InfoJsonPath  *string     `db:"info_json_path" json:"InfoJsonPath"`
	VideoID       pgtype.UUID `db:"video_id" json:"VideoID"`
	AssetScope    *string     `db:"asset_scope" json:"AssetScope"`
	ExtraArgs     []string    `db:"extra_args" json:"ExtraArgs"`
}

// DequeueIngestJob claims one queued ingest job and returns needed info.
// Returns video_id for asset regeneration jobs (NULL for normal ingest).
// Skips jobs that have already been retried too many times.
//
//	WITH cte AS (
//	    SELECT id
//	    FROM ingest_jobs
//	    WHERE status = 'queued'
//	      AND attempts < 5
//	    ORDER BY created_at
//	    LIMIT 1
//	    FOR UPDATE SKIP LOCKED
//	)
//	UPDATE ingest_jobs AS ij
//	SET status = 'processing',
//	    attempts = ij.attempts + 1,
//	    started_at = COALESCE(ij.started_at, NOW()),
//	    updated_at = NOW()
//	FROM download_jobs AS dj
//	WHERE ij.id IN (SELECT id FROM cte)
//	  AND dj.id = ij.download_job_id
//	RETURNING
//	    ij.id AS ingest_job_id,
//	    ij.download_job_id,
//	    dj.url AS url,
//	    dj.archived_by AS archived_by,
//	    dj.refresh AS refresh,
//	    dj.spool_dir AS spool_dir,
//	    dj.info_json_path AS info_json_path,
//	    dj.video_id AS video_id,
//	    ij.asset_scope AS asset_scope,
//	    dj.extra_args AS extra_args
func (q *Queries) DequeueIngestJob(ctx context.Context) (*DequeueIngestJobRow, error) {
	row := q.db.QueryRow(ctx, dequeueIngestJob)
	var i DequeueIngestJobRow
	err := row.Scan(
		&i.IngestJobID,
		&i.DownloadJobID,
		&i.URL,
		&i.ArchivedBy,
		&i.Refresh,
		&i.SpoolDir,
		&i.InfoJsonPath,
		&i.VideoID,
		&i.AssetScope,
		&i.ExtraArgs,
	)
	return &i, err
}

const enqueueAssetRegenerationJob = `-- name: EnqueueAssetRegenerationJob :one
WITH new_download_job AS (
    INSERT INTO download_jobs (
        url,
        archived_by,
        refresh,
        status,
        video_id
    )
    SELECT
        v.src,
        v.archived_by,
        true,
        'succeeded',
        v.id
    FROM videos v
    WHERE v.id = $1
    RETURNING id, created_at, updated_at, url, archived_by, status, attempts, last_error, started_at, finished_at, spool_dir, info_json_path, video_id, refresh, process_pid, archived, extra_args
),
new_ingest_job AS (
    INSERT INTO ingest_jobs (
        download_job_id,
        status,
        asset_scope
    )
    SELECT
        new_download_job.id,
        'queued',
        $2::text
    FROM new_download_job
    RETURNING id, created_at, updated_at, download_job_id, status, attempts, last_error, started_at, finished_at, asset_scope
)
SELECT
    new_ingest_job.id AS ingest_job_id,
    new_download_job.id AS download_job_id,
    new_download_job.video_id AS video_id
FROM new_ingest_job, new_download_job
`

type EnqueueAssetRegenerationJobParams struct {
	VideoID    pgtype.UUID `db:"video_id" json:"VideoID"`
	AssetScope *string     `db:"asset_scope" json:"AssetScope"`
}

type EnqueueAssetRegenerationJobRow struct {
	IngestJobID   pgtype.UUID `db:"ingest_job_id" json:"IngestJobID"`
	DownloadJobID pgtype.UUID `db:"download_job_id" json:"DownloadJobID"`
	VideoID       pgtype.UUID `db:"video_id" json:"VideoID"`
}

// EnqueueAssetRegenerationJob creates a download + ingest job pair for regenerating assets.
// asset_scope: NULL = all assets, or one of 'thumbnail', 'preview', 'seek', 'waveform'.
//
//	WITH new_download_job AS (
//	    INSERT INTO download_jobs (
//	        url,
//	        archived_by,
//	        refresh,
//	        status,
//	        video_id
//	    )
//	    SELECT
//	        v.src,
//	        v.archived_by,
//	        true,
//	        'succeeded',
//	        v.id
//	    FROM videos v
//	    WHERE v.id = $1
//	    RETURNING id, created_at, updated_at, url, archived_by, status, attempts, last_error, started_at, finished_at, spool_dir, info_json_path, video_id, refresh, process_pid, archived, extra_args
//	),
//	new_ingest_job AS (
//	    INSERT INTO ingest_jobs (
//	        download_job_id,
//	        status,
//	        asset_scope
//	    )
//	    SELECT
//	        new_download_job.id,
//	        'queued',
//	        $2::text
//	    FROM new_download_job
//	    RETURNING id, created_at, updated_at, download_job_id, status, attempts, last_error, started_at, finished_at, asset_scope
//	)
//	SELECT
//	    new_ingest_job.id AS ingest_job_id,
//	    new_download_job.id AS download_job_id,
//	    new_download_job.video_id AS video_id
//	FROM new_ingest_job, new_download_job
func (q *Queries) EnqueueAssetRegenerationJob(ctx context.Context, arg *EnqueueAssetRegenerationJobParams) (*EnqueueAssetRegenerationJobRow, error) {
	row := q.db.QueryRow(ctx, enqueueAssetRegenerationJob, arg.VideoID, arg.AssetScope)
	var i EnqueueAssetRegenerationJobRow
	err := row.Scan(&i.IngestJobID, &i.DownloadJobID, &i.VideoID)
	return &i, err
}

const enqueueDownloadJob = `-- name: EnqueueDownloadJob :one
INSERT INTO download_jobs (
    url,
    archived_by,
    status,
    refresh,
    extra_args
)
VALUES (
    $1,
    $2,
    'queued',
    $3,
    $4
)
RETURNING id, created_at, updated_at, url, archived_by, status, attempts, last_error, started_at, finished_at, spool_dir, info_json_path, video_id, refresh, process_pid, archived, extra_args
`

type EnqueueDownloadJobParams struct {
	URL        string      `db:"url" json:"Url"`
	ArchivedBy pgtype.UUID `db:"archived_by" json:"ArchivedBy"`
	Refresh    bool        `db:"refresh" json:"Refresh"`
	ExtraArgs  []string    `db:"extra_args" json:"ExtraArgs"`
}

// EnqueueDownloadJob inserts a new download job.
//
//	INSERT INTO download_jobs (
//	    url,
//	    archived_by,
//	    status,
//	    refresh,
//	    extra_args
//	)
//	VALUES (
//	    $1,
//	    $2,
//	    'queued',
//	    $3,
//	    $4
//	)
//	RETURNING id, created_at, updated_at, url, archived_by, status, attempts, last_error, started_at, finished_at, spool_dir, info_json_path, video_id, refresh, process_pid, archived, extra_args
func (q *Queries) EnqueueDownloadJob(ctx context.Context, arg *EnqueueDownloadJobParams) (*DownloadJob, error) {
	row := q.db.QueryRow(ctx, enqueueDownloadJob,
		arg.URL,
		arg.ArchivedBy,
		arg.Refresh,
		arg.ExtraArgs,
	)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.URL,
		&i.ArchivedBy,
		&i.Status,
		&i.Attempts,
		&i.LastError,
		&i.StartedAt,
		&i.FinishedAt,
		&i.SpoolDir,
		&i.InfoJsonPath,
		&i.VideoID,
		&i.Refresh,
		&i.ProcessPid,
		&i.Archived,
		&i.ExtraArgs,
	)
	return &i, err
}

const enqueueIngestJob = `-- name: EnqueueIngestJob :one
INSERT INTO ingest_jobs (
    download_job_id,
    status
)
VALUES (
    $1,
    'queued'
)
RETURNING id, created_at, updated_at, download_job_id, status, attempts, last_error, started_at, finished_at, asset_scope
`

// EnqueueIngestJob inserts a new ingest job from a download job.
//
//	INSERT INTO ingest_jobs (
//	    download_job_id,
//	    status
//	)
//	VALUES (
//	    $1,
//	    'queued'
//	)
//	RETURNING id, created_at, updated_at, download_job_id, status, attempts, last_error, started_at, finished_at, asset_scope
func (q *Queries) EnqueueIngestJob(ctx context.Context, downloadJobID pgtype.UUID) (*IngestJob, error) {
	row := q.db.QueryRow(ctx, enqueueIngestJob, downloadJobID)
	var i IngestJob
	err := row.Scan(
		&i.ID,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.DownloadJobID,
		&i.Status,
		&i.Attempts,
		&i.LastError,
		&i.StartedAt,
		&i.FinishedAt,
		&i.AssetScope,
	)
	return &i, err
}

const failExcessiveRetryIngestJobs = `-- name: FailExcessiveRetryIngestJobs :execrows
UPDATE ingest_jobs
SET status = 'failed',
    last_error = 'exceeded maximum retry attempts',
    finished_at = NOW(),
    updated_at = NOW()
WHERE status = 'queued'
  AND attempts >= 5
`

// FailExcessiveRetryIngestJobs permanently fails jobs that have been retried too many times.
// This prevents zombie jobs from wasting workers indefinitely.
//
//	UPDATE ingest_jobs
//	SET status = 'failed',
//	    last_error = 'exceeded maximum retry attempts',
//	    finished_at = NOW(),
//	    updated_at = NOW()
//	WHERE status = 'queued'
//	  AND attempts >= 5
func (q *Queries) FailExcessiveRetryIngestJobs(ctx context.Context) (int64, error) {
	result, err := q.db.Exec(ctx, failExcessiveRetryIngestJobs)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected(), nil
}

const getActiveAssetJobsForVideo = `-- name: GetActiveAssetJobsForVideo :many
SELECT ij.id AS ingest_job_id,
       ij.asset_scope,
       ij.status
FROM ingest_jobs ij
JOIN download_jobs dj ON dj.id = ij.download_job_id
WHERE dj.video_id = $1
  AND ij.status IN ('queued', 'processing')
`

type GetActiveAssetJobsForVideoRow struct {
	IngestJobID pgtype.UUID `db:"ingest_job_id" json:"IngestJobID"`
	AssetScope  *string     `db:"asset_scope" json:"AssetScope"`
	Status      JobStatus   `db:"status" json:"Status"`
}

// GetActiveAssetJobsForVideo returns active (queued/processing) ingest jobs
// for a given video, including both normal post-ingest and regen jobs.
// asset_scope is NULL for "all assets" jobs, or one of thumbnail/preview/seek/waveform.
//
//	SELECT ij.id AS ingest_job_id,
//	       ij.asset_scope,
//	       ij.status
//	FROM ingest_jobs ij
//	JOIN download_jobs dj ON dj.id = ij.download_job_id
//	WHERE dj.video_id = $1
//	  AND ij.status IN ('queued', 'processing')
func (q *Queries) GetActiveAssetJobsForVideo(ctx context.Context, videoID pgtype.UUID) ([]*GetActiveAssetJobsForVideoRow, error) {
	rows, err := q.db.Query(ctx, getActiveAssetJobsForVideo, videoID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []*GetActiveAssetJobsForVideoRow
	for rows.Next() {
		var i GetActiveAssetJobsForVideoRow
		if err := rows.Scan(&i.IngestJobID, &i.AssetScope, &i.Status); err != nil {
			return nil, err
		}
		items = append(items, &i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getDownloadJobPID = `-- name: GetDownloadJobPID :one
SELECT process_pid
FROM download_jobs
WHERE id = $1
`

// GetDownloadJobPID retrieves the process ID for a job.
//
//	SELECT process_pid
//	FROM download_jobs
//	WHERE id = $1
func (q *Queries) GetDownloadJobPID(ctx context.Context, id pgtype.UUID) (*int64, error) {
	row := q.db.QueryRow(ctx, getDownloadJobPID, id)
	var process_pid *int64
	err := row.Scan(&process_pid)
	return process_pid, err
}

const linkDownloadJobVideo = `-- name: LinkDownloadJobVideo :exec
UPDATE download_jobs
SET video_id = $1,
    updated_at = NOW()
WHERE id = $2
`

type LinkDownloadJobVideoParams struct {
	VideoID pgtype.UUID `db:"video_id" json:"VideoID"`
	ID      pgtype.UUID `db:"id" json:"ID"`
}

// LinkDownloadJobVideo stores the created video id.
//
//	UPDATE download_jobs
//	SET video_id = $1,
//	    updated_at = NOW()
//	WHERE id = $2
func (q *Queries) LinkDownloadJobVideo(ctx context.Context, arg *LinkDownloadJobVideoParams) error {
	_, err := q.db.Exec(ctx, linkDownloadJobVideo, arg.VideoID, arg.ID)
	return err
}

const markDownloadJobFailed = `-- name: MarkDownloadJobFailed :exec
UPDATE download_jobs
SET status = 'failed',
    finished_at = NOW(),
    updated_at = NOW(),
    last_error = $1
WHERE id = $2
`

type MarkDownloadJobFailedParams struct {
	LastError *string     `db:"last_error" json:"LastError"`
	ID        pgtype.UUID `db:"id" json:"ID"`
}

// MarkDownloadJobFailed stores error and marks job failed.
//
//	UPDATE download_jobs
//	SET status = 'failed',
//	    finished_at = NOW(),
//	    updated_at = NOW(),
//	    last_error = $1
//	WHERE id = $2
func (q *Queries) MarkDownloadJobFailed(ctx context.Context, arg *MarkDownloadJobFailedParams) error {
	_, err := q.db.Exec(ctx, markDownloadJobFailed, arg.LastError, arg.ID)
	return err
}

const markDownloadJobSucceeded = `-- name: MarkDownloadJobSucceeded :exec
UPDATE download_jobs
SET status = 'succeeded',
    finished_at = NOW(),
    updated_at = NOW(),
    spool_dir = $1,
    info_json_path = $2,
    last_error = NULL
WHERE id = $3
`

type MarkDownloadJobSucceededParams struct {
	SpoolDir     *string     `db:"spool_dir" json:"SpoolDir"`
	InfoJsonPath *string     `db:"info_json_path" json:"InfoJsonPath"`
	ID           pgtype.UUID `db:"id" json:"ID"`
}

// MarkDownloadJobSucceeded stores paths and marks job done.
//
//	UPDATE download_jobs
//	SET status = 'succeeded',
//	    finished_at = NOW(),
//	    updated_at = NOW(),
//	    spool_dir = $1,
//	    info_json_path = $2,
//	    last_error = NULL
//	WHERE id = $3
func (q *Queries) MarkDownloadJobSucceeded(ctx context.Context, arg *MarkDownloadJobSucceededParams) error {
	_, err := q.db.Exec(ctx, markDownloadJobSucceeded, arg.SpoolDir, arg.InfoJsonPath, arg.ID)
	return err
}

const markIngestJobFailed = `-- name: MarkIngestJobFailed :exec
UPDATE ingest_jobs
SET status = 'failed',
    finished_at = NOW(),
    updated_at = NOW(),
    last_error = $1
WHERE id = $2
`

type MarkIngestJobFailedParams struct {
	LastError *string     `db:"last_error" json:"LastError"`
	ID        pgtype.UUID `db:"id" json:"ID"`
}

// MarkIngestJobFailed marks ingest failed.
//
//	UPDATE ingest_jobs
//	SET status = 'failed',
//	    finished_at = NOW(),
//	    updated_at = NOW(),
//	    last_error = $1
//	WHERE id = $2
func (q *Queries) MarkIngestJobFailed(ctx context.Context, arg *MarkIngestJobFailedParams) error {
	_, err := q.db.Exec(ctx, markIngestJobFailed, arg.LastError, arg.ID)
	return err
}

const markIngestJobSucceeded = `-- name: MarkIngestJobSucceeded :exec
UPDATE ingest_jobs
SET status = 'succeeded',
    finished_at = NOW(),
    updated_at = NOW(),
    last_error = NULL
WHERE id = $1
`

// MarkIngestJobSucceeded marks ingest done.
//
//	UPDATE ingest_jobs
//	SET status = 'succeeded',
//	    finished_at = NOW(),
//	    updated_at = NOW(),
//	    last_error = NULL
//	WHERE id = $1
func (q *Queries) MarkIngestJobSucceeded(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, markIngestJobSucceeded, id)
	return err
}

const recoverStuckDownloadJobs = `-- name: RecoverStuckDownloadJobs :exec
UPDATE download_jobs
SET status = 'queued',
    updated_at = NOW()
WHERE status = 'processing'
  AND updated_at < NOW() - INTERVAL '5 minutes'
`

// RecoverStuckDownloadJobs resets orphaned "processing" jobs back to "queued" on service startup.
// Jobs stuck in "processing" for more than the timeout are assumed to have been orphaned by a crash or restart.
//
//	UPDATE download_jobs
//	SET status = 'queued',
//	    updated_at = NOW()
//	WHERE status = 'processing'
//	  AND updated_at < NOW() - INTERVAL '5 minutes'
func (q *Queries) RecoverStuckDownloadJobs(ctx context.Context) error {
	_, err := q.db.Exec(ctx, recoverStuckDownloadJobs)
	return err
}

const recoverStuckIngestJobs = `-- name: RecoverStuckIngestJobs :exec
UPDATE ingest_jobs
SET status = 'queued',
    updated_at = NOW()
WHERE status = 'processing'
  AND updated_at < NOW() - INTERVAL '5 minutes'
`

// RecoverStuckIngestJobs resets orphaned "processing" jobs back to "queued" on service startup.
// Jobs stuck in "processing" for more than the timeout are assumed to have been orphaned by a crash.
//
//	UPDATE ingest_jobs
//	SET status = 'queued',
//	    updated_at = NOW()
//	WHERE status = 'processing'
//	  AND updated_at < NOW() - INTERVAL '5 minutes'
func (q *Queries) RecoverStuckIngestJobs(ctx context.Context) error {
	_, err := q.db.Exec(ctx, recoverStuckIngestJobs)
	return err
}

const retryDownloadJob = `-- name: RetryDownloadJob :exec
UPDATE download_jobs
SET status = 'queued',
    last_error = NULL,
    started_at = NULL,
    finished_at = NULL,
    process_pid = NULL,
    updated_at = NOW()
WHERE id = $1
`

// RetryDownloadJob resets a job to queued status for retry.
//
//	UPDATE download_jobs
//	SET status = 'queued',
//	    last_error = NULL,
//	    started_at = NULL,
//	    finished_at = NULL,
//	    process_pid = NULL,
//	    updated_at = NOW()
//	WHERE id = $1
func (q *Queries) RetryDownloadJob(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, retryDownloadJob, id)
	return err
}

const unarchiveJob = `-- name: UnarchiveJob :exec
UPDATE download_jobs
SET archived = FALSE,
    updated_at = NOW()
WHERE id = $1
`

// UnarchiveJob unmarks a job from archived status.
//
//	UPDATE download_jobs
//	SET archived = FALSE,
//	    updated_at = NOW()
//	WHERE id = $1
func (q *Queries) UnarchiveJob(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, unarchiveJob, id)
	return err
}

const updateDownloadJobPID = `-- name: UpdateDownloadJobPID :exec
UPDATE download_jobs
SET process_pid = $1,
    updated_at = NOW()
WHERE id = $2
`

type UpdateDownloadJobPIDParams struct {
	ProcessPid *int64      `db:"process_pid" json:"ProcessPid"`
	ID         pgtype.UUID `db:"id" json:"ID"`
}

// UpdateDownloadJobPID stores the process ID of the running download.
//
//	UPDATE download_jobs
//	SET process_pid = $1,
//	    updated_at = NOW()
//	WHERE id = $2
func (q *Queries) UpdateDownloadJobPID(ctx context.Context, arg *UpdateDownloadJobPIDParams) error {
	_, err := q.db.Exec(ctx, updateDownloadJobPID, arg.ProcessPid, arg.ID)
	return err
}
